{"cells":[{"cell_type":"markdown","metadata":{"id":"GoXn14ltnGh3"},"source":["# Using an SAE as a steering vector\n","\n","This notebook demonstrates how to use SAE lens to identify a feature on a pretrained model, and then construct a steering vector to affect the models output to various prompts. This notebook will also make use of Neuronpedia for identifying features of interest.\n","\n","The steps below include:\n","\n","\n","\n","*   Installing relevant packages (Colab or locally)\n","*   Load your SAE and the model it used\n","*   Determining your feature of interest and its index\n","*   Implementing your steering vector\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gf3lJYPEXh0v"},"source":["## Setting up packages and notebook"]},{"cell_type":"markdown","metadata":{"id":"l9k5iGyOXtuN"},"source":["### Import and installs"]},{"cell_type":"markdown","metadata":{"id":"fapxk8MDrs6R"},"source":["#### Environment Setup\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"0TwNmRkRUgR7","outputId":"56437f91-c702-4251-b383-7fcdb34bab61","executionInfo":{"status":"ok","timestamp":1721824096372,"user_tz":240,"elapsed":212033,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy==1.26.4\n","  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","Successfully installed numpy-1.26.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\n","google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 7.2.1 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["try:\n","  # for google colab users\n","    import google.colab # type: ignore\n","    from google.colab import output\n","    COLAB = True\n","    #%pip install sae-lens transformer-\n","    !pip install numpy==1.26.4\n","    !pip install notebook>7.0.0 ibis-framework>=8 cudf-cu12>=24.6 sae_lens==3.9.0 transformer_lens numpy==1.26.4\n","except:\n","  # for local setup\n","    COLAB = False\n","    from IPython import get_ipython # type: ignore\n","    ipython = get_ipython(); assert ipython is not None\n","    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n","    ipython.run_line_magic(\"autoreload\", \"2\")\n","\n","# Imports for displaying vis in Colab / notebook\n","import webbrowser\n","import http.server\n","import socketserver\n","import threading\n","PORT = 8000\n","\n","# general imports\n","import os\n","import torch\n","from tqdm import tqdm\n","import plotly.express as px\n","\n","torch.set_grad_enabled(False);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGgIu1ZVYDub"},"outputs":[],"source":["def display_vis_inline(filename: str, height: int = 850):\n","    '''\n","    Displays the HTML files in Colab. Uses global `PORT` variable defined in prev cell, so that each\n","    vis has a unique port without having to define a port within the function.\n","    '''\n","    if not(COLAB):\n","        webbrowser.open(filename);\n","\n","    else:\n","        global PORT\n","\n","        def serve(directory):\n","            os.chdir(directory)\n","\n","            # Create a handler for serving files\n","            handler = http.server.SimpleHTTPRequestHandler\n","\n","            # Create a socket server with the handler\n","            with socketserver.TCPServer((\"\", PORT), handler) as httpd:\n","                print(f\"Serving files from {directory} on port {PORT}\")\n","                httpd.serve_forever()\n","\n","        thread = threading.Thread(target=serve, args=(\"/content\",))\n","        thread.start()\n","\n","        output.serve_kernel_port_as_iframe(PORT, path=f\"/{filename}\", height=height, cache_in_notebook=True)\n","\n","        PORT += 1"]},{"cell_type":"markdown","metadata":{"id":"CmaPYLpGrxbo"},"source":["#### General Installs and device setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tdUm9rZKr1Qb"},"outputs":[],"source":["# package import\n","from torch import Tensor\n","from transformer_lens import utils\n","from functools import partial\n","from jaxtyping import Int, Float\n","\n","# device setup\n","if torch.backends.mps.is_available():\n","    device = \"mps\"\n","else:\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","print(f\"Device: {device}\")"]},{"cell_type":"markdown","metadata":{"id":"lsB0qORUaXiK"},"source":["### Load your model and SAE\n","\n","We're going to work with a pretrained GPT2-small model, and the RES-JB SAE set which is for the residual stream."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["fd633e06a78a41d5b2a6759285bb61d6","95076668b0dd4e0998b8de17ddbab22b","2193291bd2d244118a0e1189b9e4f86a","c9e94c0024cd400181ad24379f740bd0","236d1535864b4cbfac1e124731f58ee8","2f21c30e39aa4a8dbecd4ab7abae518b","fe7ee3390fdd460489630b6f63099f3b","d2b232686fd24ddfb69c7a19b68ae19a","c5c53966227840199cad98266754683e","0c284a59e3c44850ae8c961eeaefadf5","f6ed5655bb3b4700be8f24d84de29197"]},"collapsed":true,"id":"bCvNtm1OOhlR","outputId":"f3a7e616-46a6-492f-f305-7ebdd39db9d5"},"outputs":[{"output_type":"stream","name":"stderr","text":["`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n","Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n","`config.hidden_activation` if you want to override this behaviour.\n","See https://github.com/huggingface/transformers/pull/29402 for more details.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd633e06a78a41d5b2a6759285bb61d6"}},"metadata":{}}],"source":["from transformer_lens import HookedTransformer\n","from sae_lens import SAE\n","from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n","from google.colab import userdata\n","import os\n","\n","os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n","\n","# Choose a layer you want to focus on\n","# For this tutorial, we're going to use layer 2\n","layer = 6\n","\n","# get model\n","model = HookedTransformer.from_pretrained(\"gemma-2b\", device = device)\n","\n","# get the SAE for this layer\n","sae, cfg_dict, _ = SAE.from_pretrained(\n","    release = \"gemma-2b-res-jb\",\n","    sae_id = f\"blocks.{layer}.hook_resid_post\",\n","    device = device\n",")\n","\n","# get hook point\n","hook_point = sae.cfg.hook_name\n","print(hook_point)"]},{"cell_type":"markdown","metadata":{"id":"NkAAoyFbu5a5"},"source":["## Determine your feature of interest and its index"]},{"cell_type":"markdown","metadata":{"id":"DkQNvdd54q4S"},"source":["### Find your feature"]},{"cell_type":"markdown","metadata":{"id":"wzeY2D13xRjY"},"source":["#### Explore through code by using the feature activations for a prompt\n","\n","For the purpose of the tutorial, we are selecting a simple token prompt.\n","\n","In this example we will look trying to find and steer a \"Jedi\" feature.\n","\n","We run our prompt on our model and get the cache, which we then use with our sae to get our feature activations.\n","\n","Now we'll look at the top feature activations and look them up on Neuronpedia to determine what they have been intepreted as."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIrdJ36mlXgB"},"outputs":[],"source":["sv_prompt = \" The Golden Gate Bridge\"\n","sv_logits, cache = model.run_with_cache(sv_prompt, prepend_bos=True)\n","tokens = model.to_tokens(sv_prompt)\n","print(tokens)\n","\n","# get the feature activations from our SAE\n","sv_feature_acts = sae.encode(cache[hook_point])\n","\n","# get sae_out\n","sae_out = sae.decode(sv_feature_acts)\n","\n","# print out the top activations, focus on the indices\n","print(torch.topk(sv_feature_acts, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_LBNbMfHu6IF"},"outputs":[],"source":["from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n","get_neuronpedia_quick_list(torch.topk(sv_feature_acts, 3).indices.tolist(), layer = layer, model = \"gemma-2b\", dataset=\"res-jb\")"]},{"cell_type":"markdown","metadata":{"id":"7hy8RbbyTb8n"},"source":["As we can see from our print out of tokens, the prompt is made of three tokens in total - \"<endoftext>\", \"J\", and \"edi\".\n","\n","Our feature activation indexes at sv_feature_acts[2] - for \"edi\" - are of most interest to us.\n","\n","Because we are using pretrained saes that have published feature maps, you can search on Neuronpedia for a feature of interest."]},{"cell_type":"markdown","metadata":{"id":"gFv4iBHFcOmE"},"source":["### Steps for Neuronpedia use\n","\n","Use the interface to search for a specific concept or item and determine which layer and at what index it is.\n","\n","1.   Open the [Neuronpedia](https://www.neuronpedia.org/) homepage.\n","2.   Using the \"Models\" dropdown, select your model. Here we are using GPT2-SM (GPT2-small).\n","3.   The next page will have a search bar, which allows you to enter your index of interest. We're interested in the \"RES-JB\" SAE set, make sure to select it.\n","4.   We found these indices in the previous step: [ 7650,   718, 22372]. Select them in the search to see the feature dashboard for each.\n","5.   As we'll see, some of the indices may relate to features you don't care about.\n","\n","From using Neuronpedia, I have determined that my feature of interest is in layer 2, at index 7650: [here](https://www.neuronpedia.org/gpt2-small/2-res-jb/7650) is the feature."]},{"cell_type":"markdown","metadata":{"id":"KX0rXziniH9O"},"source":["### Note: 2nd Option - Starting with Neuronpedia\n","\n","Another option here is that you can start with Neuronpedia to identify features of interest. By using your prompt in the interface you can explore which features were involved and search across all the layers. This allows you to first determine your layer and index of interest in Neuronpedia before focusing them in your code. Start [here](https://www.neuronpedia.org/search) if you want to begin with search."]},{"cell_type":"markdown","metadata":{"id":"YACtNFzGcNua"},"source":["## Implement your steering vector and affect the output"]},{"cell_type":"markdown","metadata":{"id":"pO8hjg8j5bb-"},"source":["### Define values for your steering vector\n","To create our steering vector, we now need to get the decoder weights from our sparse autoencoder found at our index of interest.\n","\n","Then to use our steering vector, we want a prompt for text generation, as well as a scaling factor coefficent to apply with the steering vector\n","\n","We also set common sampling kwargs - temperature, top_p and freq_penalty"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rgYEWGV0t0L2"},"outputs":[],"source":["steering_vector = sae.W_dec[10200]\n","\n","example_prompt = \"What is the most iconic structure known to man?\"\n","coeff = 300\n","sampling_kwargs = dict(temperature=1.0, top_p=0.1, freq_penalty=1.0)"]},{"cell_type":"markdown","metadata":{"id":"cexaoBR65lIa"},"source":["### Set up hook functions\n","\n","Finally, we need to create a hook that allows us to apply the steering vector when our model runs generate() on our defined prompt. We have also added a boolean value 'steering_on' that allows us to easily toggle the steering vector on and off for each prompt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"3kcVWeJoIAlC"},"outputs":[],"source":["def steering_hook(resid_pre, hook):\n","    if resid_pre.shape[1] == 1:\n","        return\n","\n","    position = sae_out.shape[1]\n","    if steering_on:\n","      # using our steering vector and applying the coefficient\n","      resid_pre[:, :position - 1, :] += coeff * steering_vector\n","\n","\n","def hooked_generate(prompt_batch, fwd_hooks=[], seed=None, **kwargs):\n","    if seed is not None:\n","        torch.manual_seed(seed)\n","\n","    with model.hooks(fwd_hooks=fwd_hooks):\n","        tokenized = model.to_tokens(prompt_batch)\n","        result = model.generate(\n","            stop_at_eos=False,  # avoids a bug on MPS\n","            input=tokenized,\n","            max_new_tokens=50,\n","            do_sample=True,\n","            **kwargs)\n","    return result\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VcuRkX0yA2WH"},"outputs":[],"source":["def run_generate(example_prompt):\n","  model.reset_hooks()\n","  editing_hooks = [(f\"blocks.{layer}.hook_resid_post\", steering_hook)]\n","  res = hooked_generate([example_prompt] * 3, editing_hooks, seed=None, **sampling_kwargs)\n","\n","  # Print results, removing the ugly beginning of sequence token\n","  res_str = model.to_string(res[:, 1:])\n","  print((\"\\n\\n\" + \"-\" * 80 + \"\\n\\n\").join(res_str))"]},{"cell_type":"markdown","metadata":{"id":"XYx--hIn61VQ"},"source":["### Generate text influenced by steering vector\n","\n","You may want to experiment with the scaling factor coefficient value that you set and see how it affects the generated output."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hN_YOzBE6lz8"},"outputs":[],"source":["steering_on = True\n","run_generate(example_prompt)"]},{"cell_type":"markdown","metadata":{"id":"ltZEm1VW7Tsr"},"source":["### Generate text with no steering"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"nA9cs1BY7XhS"},"outputs":[],"source":["steering_on = False\n","run_generate(example_prompt)"]},{"cell_type":"markdown","metadata":{"id":"Q_duIXtnAcj9"},"source":["### General Question test\n","We'll also attempt a more general prompt which is a better indication of whether our steering vector is having an effect or not"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UmqQEAM3Ab0i"},"outputs":[],"source":["question_prompt = \"What is on your mind?\"\n","coeff = 100\n","sampling_kwargs = dict(temperature=1.0, top_p=0.1, freq_penalty=1.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUanDPQeAss3"},"outputs":[],"source":["steering_on = True\n","run_generate(question_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W07bAiWqBlXh"},"outputs":[],"source":["steering_on = False\n","run_generate(question_prompt)"]},{"cell_type":"markdown","metadata":{"id":"JVTbMgMzCLB9"},"source":["## Next Steps\n","\n","Ideas you could take for further exploration:\n","\n","*   Try ablating the feature\n","*   Try and get a response where just the feature token prints over and over\n","*   Investigate other features with more complex usage\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["fapxk8MDrs6R","CmaPYLpGrxbo"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"vscode":{"interpreter":{"hash":"088c6e4e32c1710b3b346fe2c9e3084abd3190c888871e6e5b66f23c765b3959"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"fd633e06a78a41d5b2a6759285bb61d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95076668b0dd4e0998b8de17ddbab22b","IPY_MODEL_2193291bd2d244118a0e1189b9e4f86a","IPY_MODEL_c9e94c0024cd400181ad24379f740bd0"],"layout":"IPY_MODEL_236d1535864b4cbfac1e124731f58ee8"}},"95076668b0dd4e0998b8de17ddbab22b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f21c30e39aa4a8dbecd4ab7abae518b","placeholder":"​","style":"IPY_MODEL_fe7ee3390fdd460489630b6f63099f3b","value":"Loading checkpoint shards: 100%"}},"2193291bd2d244118a0e1189b9e4f86a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2b232686fd24ddfb69c7a19b68ae19a","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5c53966227840199cad98266754683e","value":2}},"c9e94c0024cd400181ad24379f740bd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c284a59e3c44850ae8c961eeaefadf5","placeholder":"​","style":"IPY_MODEL_f6ed5655bb3b4700be8f24d84de29197","value":" 2/2 [00:25&lt;00:00, 10.38s/it]"}},"236d1535864b4cbfac1e124731f58ee8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f21c30e39aa4a8dbecd4ab7abae518b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe7ee3390fdd460489630b6f63099f3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2b232686fd24ddfb69c7a19b68ae19a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5c53966227840199cad98266754683e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0c284a59e3c44850ae8c961eeaefadf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6ed5655bb3b4700be8f24d84de29197":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}