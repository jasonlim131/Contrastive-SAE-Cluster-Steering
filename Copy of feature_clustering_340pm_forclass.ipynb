{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1qUdsegUIZILv5DDLVStH6GTIz-ZhFmKH","timestamp":1720294736689},{"file_id":"1yCZvzm71J9B_KGt9O8xge2fgw1pvkRMQ","timestamp":1718704649080}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5fa3ffa17d1c4c389a9f11768ff1e7b8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d3d9fad22954974a0346d02f694b5d4","IPY_MODEL_bc3ad7e81baf4d7db350312f9388e997","IPY_MODEL_f0b8de0ec9fd41a8ad388060062ce79a"],"layout":"IPY_MODEL_81ace3d80c414426a39fe64123a52a28"}},"8d3d9fad22954974a0346d02f694b5d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_859ad9c1b3a0433882932ee74dc71c89","placeholder":"​","style":"IPY_MODEL_4b6020415e164d6893d2b7f4d8a61b6d","value":"tokenizer_config.json: 100%"}},"bc3ad7e81baf4d7db350312f9388e997":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_485b14c8dde04ae3967555f0bdc4c1f0","max":33556,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa634657bbc148249d9ebe926f640d13","value":33556}},"f0b8de0ec9fd41a8ad388060062ce79a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcdfe3ec4a9946ed880e403c0a8c9292","placeholder":"​","style":"IPY_MODEL_5d08c23e82a54adbab4dce7417a64ef3","value":" 33.6k/33.6k [00:00&lt;00:00, 2.14MB/s]"}},"81ace3d80c414426a39fe64123a52a28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"859ad9c1b3a0433882932ee74dc71c89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b6020415e164d6893d2b7f4d8a61b6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"485b14c8dde04ae3967555f0bdc4c1f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa634657bbc148249d9ebe926f640d13":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fcdfe3ec4a9946ed880e403c0a8c9292":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d08c23e82a54adbab4dce7417a64ef3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11809105110c489090c58a92f2eb81f2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edda6322278749b9a96a0153ad05e0ee","IPY_MODEL_7ca7ae443b5940c89598a2682e97831a","IPY_MODEL_a2b2afcbaa2a449aa3242e00827afcb9"],"layout":"IPY_MODEL_3a02b87f92a34e0485ba55ccc28d5a4c"}},"edda6322278749b9a96a0153ad05e0ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97937598e5514b1b8506a64c2d090c75","placeholder":"​","style":"IPY_MODEL_b3aa161bb6e64b4b9165ddb2501a82fd","value":"tokenizer.model: 100%"}},"7ca7ae443b5940c89598a2682e97831a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97a582b4b004432fafeec417637240ea","max":4241003,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34bf96dbe4194cfba5b3c689b3f3beae","value":4241003}},"a2b2afcbaa2a449aa3242e00827afcb9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e55b155bd294b109b818dc9f740ded6","placeholder":"​","style":"IPY_MODEL_3e867c1f259c47ba825cea244f380035","value":" 4.24M/4.24M [00:00&lt;00:00, 15.3MB/s]"}},"3a02b87f92a34e0485ba55ccc28d5a4c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97937598e5514b1b8506a64c2d090c75":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3aa161bb6e64b4b9165ddb2501a82fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97a582b4b004432fafeec417637240ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34bf96dbe4194cfba5b3c689b3f3beae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3e55b155bd294b109b818dc9f740ded6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e867c1f259c47ba825cea244f380035":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef19fa29695c4ed7bac16863b8894543":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdd9ee241f0f46718bb4495c17a8f75d","IPY_MODEL_402e2112effc4362aae4deb9610a6ab6","IPY_MODEL_ebd0d5c88e0d47589fd0c9117f62ec8c"],"layout":"IPY_MODEL_0375306c4e414bd4b7edcf9e23861eb6"}},"bdd9ee241f0f46718bb4495c17a8f75d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_49f4fa99cf7f48fd84beeec8adf33001","placeholder":"​","style":"IPY_MODEL_bd289b2c249d4184b7b4d04543864c1e","value":"tokenizer.json: 100%"}},"402e2112effc4362aae4deb9610a6ab6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_99a921d6b64e4bc599bc93e799c813f0","max":17518497,"min":0,"orientation":"horizontal","style":"IPY_MODEL_220f262b298e44aaac44e28a0de964be","value":17518497}},"ebd0d5c88e0d47589fd0c9117f62ec8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f240807b554431abd33c7e134658f12","placeholder":"​","style":"IPY_MODEL_82290620353b43f39ca3ee99305fe06a","value":" 17.5M/17.5M [00:00&lt;00:00, 60.3MB/s]"}},"0375306c4e414bd4b7edcf9e23861eb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49f4fa99cf7f48fd84beeec8adf33001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd289b2c249d4184b7b4d04543864c1e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"99a921d6b64e4bc599bc93e799c813f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"220f262b298e44aaac44e28a0de964be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f240807b554431abd33c7e134658f12":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82290620353b43f39ca3ee99305fe06a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21b0a6e18bfe495fbd2f5562c726a4f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ce78b20166143babee7946ba64cafae","IPY_MODEL_521a7afbc08f4aa09b844062cd3418a3","IPY_MODEL_f6c4d968e20b4e69b00d183cd86aab17"],"layout":"IPY_MODEL_fc82d61ac46b477b8cadbc6ce4e5c1d3"}},"4ce78b20166143babee7946ba64cafae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de7cb68bfb38426c85c6c509dfb4c6ea","placeholder":"​","style":"IPY_MODEL_2977e7e046e442f9b84060d9f9852a38","value":"special_tokens_map.json: 100%"}},"521a7afbc08f4aa09b844062cd3418a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c01d9f78d9d9467b95b4ea2ae2d87f64","max":636,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afe26f55b74a4d89bf41ed61f009eda4","value":636}},"f6c4d968e20b4e69b00d183cd86aab17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1c8d51db59a438e98a8880b6237e5db","placeholder":"​","style":"IPY_MODEL_52ac43164bf74c00b925afc8ea5c9ba0","value":" 636/636 [00:00&lt;00:00, 36.6kB/s]"}},"fc82d61ac46b477b8cadbc6ce4e5c1d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de7cb68bfb38426c85c6c509dfb4c6ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2977e7e046e442f9b84060d9f9852a38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c01d9f78d9d9467b95b4ea2ae2d87f64":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afe26f55b74a4d89bf41ed61f009eda4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d1c8d51db59a438e98a8880b6237e5db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52ac43164bf74c00b925afc8ea5c9ba0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57de5a7efd2c4ade825ae82deb1fcdce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb65e3910f7d4f778ba3ceeb89ebd069","IPY_MODEL_9384e134671d4b6286437c4b81f3f9eb","IPY_MODEL_5e70e88f69884eabbb1c410a7c736857"],"layout":"IPY_MODEL_3c0e45b995534534a98b786ef2e2ba55"}},"cb65e3910f7d4f778ba3ceeb89ebd069":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90090d8a640a4e848f54d6ba493e4322","placeholder":"​","style":"IPY_MODEL_b92573e791f74828a5db485829ad7035","value":"config.json: 100%"}},"9384e134671d4b6286437c4b81f3f9eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_905e46a8c6cb4b288865cf56686ff762","max":627,"min":0,"orientation":"horizontal","style":"IPY_MODEL_016fd869396448c284be056fcfb96fdf","value":627}},"5e70e88f69884eabbb1c410a7c736857":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc462de1d5f04d299942cc2917ac2e39","placeholder":"​","style":"IPY_MODEL_835fc0261ad84c20a708c57e2d418952","value":" 627/627 [00:00&lt;00:00, 35.6kB/s]"}},"3c0e45b995534534a98b786ef2e2ba55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90090d8a640a4e848f54d6ba493e4322":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92573e791f74828a5db485829ad7035":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"905e46a8c6cb4b288865cf56686ff762":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"016fd869396448c284be056fcfb96fdf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc462de1d5f04d299942cc2917ac2e39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"835fc0261ad84c20a708c57e2d418952":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dfc7bfca9c5142db99613bba34f5f5d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6233225de30c4c53a91cfae7a0944a6e","IPY_MODEL_9a0af0eec9ca465d9d4e19e63a0618ff","IPY_MODEL_01a2ae5a0f60426ba14d8c78950c9476"],"layout":"IPY_MODEL_f16dc6eccbd545a0b8b4b78ce44f1fe0"}},"6233225de30c4c53a91cfae7a0944a6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6ddda72e44647109bd5a5c7c4e78f5c","placeholder":"​","style":"IPY_MODEL_b9c7821effb74d3e9ae1f245f5604587","value":"model.safetensors.index.json: 100%"}},"9a0af0eec9ca465d9d4e19e63a0618ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43a7b4b6561c49eeba414bcae98145e8","max":13489,"min":0,"orientation":"horizontal","style":"IPY_MODEL_01ea2ff250954aa0827fab63fe2fbc7a","value":13489}},"01a2ae5a0f60426ba14d8c78950c9476":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_98e62f4e48b442109edc3314d8bf1d94","placeholder":"​","style":"IPY_MODEL_98123449691e43f4bfc6ef606ffec23c","value":" 13.5k/13.5k [00:00&lt;00:00, 521kB/s]"}},"f16dc6eccbd545a0b8b4b78ce44f1fe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6ddda72e44647109bd5a5c7c4e78f5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9c7821effb74d3e9ae1f245f5604587":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43a7b4b6561c49eeba414bcae98145e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01ea2ff250954aa0827fab63fe2fbc7a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"98e62f4e48b442109edc3314d8bf1d94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98123449691e43f4bfc6ef606ffec23c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9572bb5a21f846debfc9a049cd2329c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_83176dcd72a0468992c53295476e2fc7","IPY_MODEL_0237455e51d6446f8b4aaaf975f8e3ac","IPY_MODEL_2d1e22f591454e05a5c0d1456109441e"],"layout":"IPY_MODEL_44ce33b1f5a04af0b5bed32032699847"}},"83176dcd72a0468992c53295476e2fc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e464894752834e8e921ec860cab55117","placeholder":"​","style":"IPY_MODEL_6134cb050863492db2ff95be8c24b8e0","value":"Downloading shards: 100%"}},"0237455e51d6446f8b4aaaf975f8e3ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a62ee8ed9244c549a3ae0fbb61e9746","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_30614434a96a4a98bb6ad7a9b9536458","value":2}},"2d1e22f591454e05a5c0d1456109441e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df34a86f000342e8aa64e51ecb5f2d18","placeholder":"​","style":"IPY_MODEL_e7ccef89f0fb411bb9e2ec667a56df43","value":" 2/2 [00:46&lt;00:00, 19.41s/it]"}},"44ce33b1f5a04af0b5bed32032699847":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e464894752834e8e921ec860cab55117":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6134cb050863492db2ff95be8c24b8e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a62ee8ed9244c549a3ae0fbb61e9746":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30614434a96a4a98bb6ad7a9b9536458":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df34a86f000342e8aa64e51ecb5f2d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7ccef89f0fb411bb9e2ec667a56df43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4e2602c35fd4232ae05fb7b36467e9f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d1ae58cedad840b49def4b313b230f88","IPY_MODEL_c09a431eaf234b4181811b35f5bc4cac","IPY_MODEL_d68fc6d799a946aa84e4045861e45566"],"layout":"IPY_MODEL_4f8c85dcb918439f91b9b335135a7724"}},"d1ae58cedad840b49def4b313b230f88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cfc0df4ce744e2ea9e040842ccbceb7","placeholder":"​","style":"IPY_MODEL_052c2dfa20614f28a74b34ec44a420be","value":"model-00001-of-00002.safetensors: 100%"}},"c09a431eaf234b4181811b35f5bc4cac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0f622bf13f0481f99fff36bcfcf1ef6","max":4945242264,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3adec10ec394fb89effbb2ef9ab1bce","value":4945242264}},"d68fc6d799a946aa84e4045861e45566":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5aa2a3e0ec3240ed9529013c0a794674","placeholder":"​","style":"IPY_MODEL_7065a44e12c842fa8fb06dba60993fc9","value":" 4.95G/4.95G [00:46&lt;00:00, 107MB/s]"}},"4f8c85dcb918439f91b9b335135a7724":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cfc0df4ce744e2ea9e040842ccbceb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"052c2dfa20614f28a74b34ec44a420be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0f622bf13f0481f99fff36bcfcf1ef6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3adec10ec394fb89effbb2ef9ab1bce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5aa2a3e0ec3240ed9529013c0a794674":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7065a44e12c842fa8fb06dba60993fc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edbfa156a90a4d469165b7eed2d63d87":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_501a0f63d38f44c09bc3630dcb091937","IPY_MODEL_df04e81ba1af4e4a928addbb0691876b","IPY_MODEL_8735bcee310744b7afdbec883506499e"],"layout":"IPY_MODEL_36f3bb3ce120494494bcb86a6d3f9c17"}},"501a0f63d38f44c09bc3630dcb091937":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_357b0e7012d0409d844743337999deab","placeholder":"​","style":"IPY_MODEL_3d5898e5d9ad4c77812fb7d26d794247","value":"model-00002-of-00002.safetensors: 100%"}},"df04e81ba1af4e4a928addbb0691876b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_993b9fb55b2b4216b9564895eb643615","max":67121608,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2e73d6e83ff44c53ba463b8780322ab9","value":67121608}},"8735bcee310744b7afdbec883506499e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0ba34db2ac445529c6e4e326027ca69","placeholder":"​","style":"IPY_MODEL_0261d7ba5747456b938f9207f0ce36cf","value":" 67.1M/67.1M [00:00&lt;00:00, 144MB/s]"}},"36f3bb3ce120494494bcb86a6d3f9c17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"357b0e7012d0409d844743337999deab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d5898e5d9ad4c77812fb7d26d794247":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"993b9fb55b2b4216b9564895eb643615":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e73d6e83ff44c53ba463b8780322ab9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e0ba34db2ac445529c6e4e326027ca69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0261d7ba5747456b938f9207f0ce36cf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51cf7cb4d7f24a0baf9cfc0472b2e7a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_522394fb6a70462a80cfa721b8f2e97e","IPY_MODEL_cc97ff08a0ee4d818bc6f78f3296131a","IPY_MODEL_ee3567375f8449ef93d7fdb0735124cc"],"layout":"IPY_MODEL_46ad490e469f40eaa90265eccfcd5bff"}},"522394fb6a70462a80cfa721b8f2e97e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a766483672c547509a9368e3f1d950f9","placeholder":"​","style":"IPY_MODEL_e8d51601721c4c8c88d869217445d284","value":"Loading checkpoint shards: 100%"}},"cc97ff08a0ee4d818bc6f78f3296131a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_377c0946605f4a42ac53873be4e31a57","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_047f1c0bd0404a0c97a73137c541d49c","value":2}},"ee3567375f8449ef93d7fdb0735124cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b79668988f2f45ef8d19f9a583d770d7","placeholder":"​","style":"IPY_MODEL_f6eae777d25e4186abd1611c09cfbf08","value":" 2/2 [00:30&lt;00:00, 12.63s/it]"}},"46ad490e469f40eaa90265eccfcd5bff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a766483672c547509a9368e3f1d950f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8d51601721c4c8c88d869217445d284":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"377c0946605f4a42ac53873be4e31a57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"047f1c0bd0404a0c97a73137c541d49c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b79668988f2f45ef8d19f9a583d770d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6eae777d25e4186abd1611c09cfbf08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"474e005f036a43dc98546668dcc10230":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be6597dc3dab4c98af0945878e000c5a","IPY_MODEL_b73f808e8f4648b3aa76cdf198186a38","IPY_MODEL_5ac758653db44a008c3942fb55135065"],"layout":"IPY_MODEL_f5a2f68ae05f4ed7801c82a260a590ea"}},"be6597dc3dab4c98af0945878e000c5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c43577cd73e4787ad2050ae2f680c3b","placeholder":"​","style":"IPY_MODEL_13664e911b024cfd82e70b3870abbae1","value":"generation_config.json: 100%"}},"b73f808e8f4648b3aa76cdf198186a38":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17ae0bc61212462da1df235bf7e6114a","max":137,"min":0,"orientation":"horizontal","style":"IPY_MODEL_31d8649416a54886a864b9b88f740839","value":137}},"5ac758653db44a008c3942fb55135065":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b4bde7d35c54cbaab87cf15a6424088","placeholder":"​","style":"IPY_MODEL_f8e7850c1e6f42ab88d53b98196d200c","value":" 137/137 [00:00&lt;00:00, 10.1kB/s]"}},"f5a2f68ae05f4ed7801c82a260a590ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c43577cd73e4787ad2050ae2f680c3b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13664e911b024cfd82e70b3870abbae1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17ae0bc61212462da1df235bf7e6114a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31d8649416a54886a864b9b88f740839":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b4bde7d35c54cbaab87cf15a6424088":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8e7850c1e6f42ab88d53b98196d200c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Intro\n","Typically we use cosine similarity as a proxy for relatedness of features.  \n","Normally to find nearest neighbors you would have to check all pairwise distances.  \n","\n","By using a hierarchical clustering method in advance, we can precompute these to make retrieval near instant at inference time.\n","\n","\n","This indexing data over feature space takes minimal space: about 9 MB for ~300k features across the 12 layers of GPT2-small.  \n","It takes about 4 minutes per layer of ~25k features to compute, or about 45 minutes for all layers. These were all saved to a pkl."],"metadata":{"id":"vXMK1fds7cpH"}},{"cell_type":"code","source":["# mount your drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hXMRYgFAjAsY","executionInfo":{"status":"ok","timestamp":1720297679255,"user_tz":240,"elapsed":1241,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}},"outputId":"b8400078-f7ed-4c3f-c704-525f42e65996"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Need to install it in this order\n","# Numpy causes problems with different version dependencies\n","# But 1.25.2 seems to work for everything\n","!pip install circuitsvis\n","!pip install nnsight transformer_lens sae-lens==3.9.0\n","!pip install bitsandbytes\n","!pip install numpy==1.25.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"yFWpFjurmlrc","outputId":"732f6161-1cf8-4a8a-c882-5723933e1cb4","executionInfo":{"status":"ok","timestamp":1720297782238,"user_tz":240,"elapsed":102989,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: circuitsvis in /usr/local/lib/python3.10/dist-packages (1.43.2)\n","Requirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.0.0)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (1.25.2)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.3.1)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.9.2.26)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (12.1.105)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->circuitsvis) (12.5.82)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.1.0->circuitsvis) (3.15.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.19.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (2023.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->circuitsvis) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->circuitsvis) (1.3.0)\n","Requirement already satisfied: nnsight in /usr/local/lib/python3.10/dist-packages (0.2.19)\n","Requirement already satisfied: transformer_lens in /usr/local/lib/python3.10/dist-packages (1.19.0)\n","Requirement already satisfied: sae-lens==3.9.0 in /usr/local/lib/python3.10/dist-packages (3.9.0)\n","Requirement already satisfied: automated-interpretability<0.0.4,>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (0.0.3)\n","Requirement already satisfied: babe<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (0.0.7)\n","Requirement already satisfied: datasets<3.0.0,>=2.17.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (2.20.0)\n","Requirement already satisfied: matplotlib<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (3.9.1)\n","Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (0.1.7)\n","Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (3.8.1)\n","Requirement already satisfied: plotly<6.0.0,>=5.19.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (5.22.0)\n","Requirement already satisfied: plotly-express<0.5.0,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (0.4.1)\n","Requirement already satisfied: pytest-profiling<2.0.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (1.7.0)\n","Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (1.0.1)\n","Requirement already satisfied: pyyaml<7.0.0,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (6.0.1)\n","Requirement already satisfied: pyzmq==26.0.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (26.0.0)\n","Requirement already satisfied: sae-vis<0.3.0,>=0.2.18 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (0.2.19)\n","Requirement already satisfied: safetensors<0.5.0,>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (0.4.3)\n","Requirement already satisfied: transformers<5.0.0,>=4.38.1 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (4.41.2)\n","Requirement already satisfied: typer<0.13.0,>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (0.12.3)\n","Requirement already satisfied: zstandard<0.23.0,>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from sae-lens==3.9.0) (0.22.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from nnsight) (3.20.3)\n","Requirement already satisfied: python-socketio[client] in /usr/local/lib/python3.10/dist-packages (from nnsight) (5.11.3)\n","Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from nnsight) (0.19.1)\n","Requirement already satisfied: pydantic>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from nnsight) (2.8.0)\n","Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from nnsight) (2.1.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from nnsight) (0.1.99)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from nnsight) (0.18.0+cu121)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from nnsight) (0.32.1)\n","Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from nnsight) (0.29.2)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from nnsight) (0.7.0)\n","Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.14.1)\n","Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n","Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n","Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.31)\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.25.2)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.0.3)\n","Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.7.1)\n","Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.12.2)\n","Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.17.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->nnsight) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->nnsight) (5.9.5)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->nnsight) (0.23.4)\n","Requirement already satisfied: blobfile<3.0.0,>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (2.1.1)\n","Requirement already satisfied: boostedblob<0.16.0,>=0.15.3 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (0.15.3)\n","Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (0.27.0)\n","Collecting numpy>=1.24 (from transformer_lens)\n","  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","Requirement already satisfied: orjson<4.0.0,>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (3.10.6)\n","Requirement already satisfied: pytest<9.0.0,>=8.1.2 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (8.2.2)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (1.5.1)\n","Requirement already satisfied: tiktoken<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (0.6.0)\n","Requirement already satisfied: py2store in /usr/local/lib/python3.10/dist-packages (from babe<0.0.8,>=0.0.7->sae-lens==3.9.0) (0.1.20)\n","Requirement already satisfied: graze in /usr/local/lib/python3.10/dist-packages (from babe<0.0.8,>=0.0.7->sae-lens==3.9.0) (0.1.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (3.15.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (0.3.8)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (2.32.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (3.9.5)\n","Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens==3.9.0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens==3.9.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens==3.9.0) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens==3.9.0) (1.4.5)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens==3.9.0) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens==3.9.0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4.0.0,>=3.8.3->sae-lens==3.9.0) (2.8.2)\n","Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline<0.2.0,>=0.1.6->sae-lens==3.9.0) (5.7.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens==3.9.0) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens==3.9.0) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->sae-lens==3.9.0) (2024.5.15)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly<6.0.0,>=5.19.0->sae-lens==3.9.0) (8.4.2)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens==3.9.0) (0.14.2)\n","Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens==3.9.0) (1.11.4)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.10/dist-packages (from plotly-express<0.5.0,>=0.4.1->sae-lens==3.9.0) (0.5.6)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4.0->nnsight) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4.0->nnsight) (2.20.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens==3.9.0) (1.16.0)\n","Requirement already satisfied: gprof2dot in /usr/local/lib/python3.10/dist-packages (from pytest-profiling<2.0.0,>=1.7.0->sae-lens==3.9.0) (2024.6.6)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.16.1)\n","Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.4 in /usr/local/lib/python3.10/dist-packages (from sae-vis<0.3.0,>=0.2.18->sae-lens==3.9.0) (0.6.7)\n","Requirement already satisfied: eindex-callum<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from sae-vis<0.3.0,>=0.2.18->sae-lens==3.9.0) (0.1.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (2.18.1)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (12.1.105)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->nnsight) (2.1.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.1.0->nnsight) (12.5.82)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.13.0,>=0.12.3->sae-lens==3.9.0) (1.5.4)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.2.2)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (2.7.1)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (67.7.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->nnsight) (8.0.0)\n","Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio[client]->nnsight) (0.23.1)\n","Requirement already satisfied: python-engineio>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio[client]->nnsight) (4.9.1)\n","Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio[client]->nnsight) (1.8.0)\n","Collecting torch>=2.1.0 (from nnsight)\n","  Using cached torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.1.0->nnsight)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting triton==2.3.0 (from torch>=2.1.0->nnsight)\n","  Using cached triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","Requirement already satisfied: pycryptodomex~=3.8 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (3.20.0)\n","Requirement already satisfied: urllib3<3,>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (2.0.7)\n","Requirement already satisfied: lxml~=4.9 in /usr/local/lib/python3.10/dist-packages (from blobfile<3.0.0,>=2.1.1->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (4.9.4)\n","Requirement already satisfied: uvloop>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from boostedblob<0.16.0,>=0.15.3->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (0.19.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (4.0.3)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7.0,>=0.6.4->sae-vis<0.3.0,>=0.2.18->sae-lens==3.9.0) (3.21.3)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7.0,>=0.6.4->sae-vis<0.3.0,>=0.2.18->sae-lens==3.9.0) (0.9.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (2024.6.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (1.0.5)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (3.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (0.14.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (2.0.0)\n","Requirement already satisfied: pluggy<2.0,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (1.5.0)\n","Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (1.2.1)\n","Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=8.1.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (2.0.1)\n","Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from python-engineio>=4.8.0->python-socketio[client]->nnsight) (1.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<3.0.0,>=2.17.1->sae-lens==3.9.0) (3.3.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2.0.0,>=1.4.2->automated-interpretability<0.0.4,>=0.0.3->sae-lens==3.9.0) (3.5.0)\n","Requirement already satisfied: dol in /usr/local/lib/python3.10/dist-packages (from graze->babe<0.0.8,>=0.0.7->sae-lens==3.9.0) (0.2.49)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->nnsight) (3.19.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->nnsight) (2.1.5)\n","Requirement already satisfied: config2py in /usr/local/lib/python3.10/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens==3.9.0) (0.1.33)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from py2store->babe<0.0.8,>=0.0.7->sae-lens==3.9.0) (6.4.0)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.0->nnsight) (1.3.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n","Requirement already satisfied: wsproto in /usr/local/lib/python3.10/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio[client]->nnsight) (1.2.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.4->sae-vis<0.3.0,>=0.2.18->sae-lens==3.9.0) (1.0.0)\n","Requirement already satisfied: i2 in /usr/local/lib/python3.10/dist-packages (from config2py->py2store->babe<0.0.8,>=0.0.7->sae-lens==3.9.0) (0.1.17)\n","Installing collected packages: triton, nvidia-nccl-cu12, numpy, torch\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.18.1\n","    Uninstalling nvidia-nccl-cu12-2.18.1:\n","      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.2\n","    Uninstalling torch-2.1.2:\n","      Successfully uninstalled torch-2.1.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","circuitsvis 1.43.2 requires nvidia-nccl-cu12==2.18.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.20.5 which is incompatible.\n","circuitsvis 1.43.2 requires triton==2.1.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 2.3.0 which is incompatible.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4 nvidia-nccl-cu12-2.20.5 torch-2.3.0 triton-2.3.0\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n","Installing collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.1\n","Collecting numpy==1.25.2\n","  Using cached numpy-1.25.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n","Installing collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.26.4\n","    Uninstalling numpy-1.26.4:\n","      Successfully uninstalled numpy-1.26.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","automated-interpretability 0.0.3 requires numpy<2.0.0,>=1.26.4, but you have numpy 1.25.2 which is incompatible.\n","circuitsvis 1.43.2 requires nvidia-nccl-cu12==2.18.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nccl-cu12 2.20.5 which is incompatible.\n","circuitsvis 1.43.2 requires triton==2.1.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 2.3.0 which is incompatible.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.25.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"068c731240514e138de0df43e1637905"}},"metadata":{}}]},{"cell_type":"code","source":["import numpy as np\n","print(np.__version__)\n","!pip show numpy"],"metadata":{"id":"GG4tuplkCzFp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720297790342,"user_tz":240,"elapsed":8122,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}},"outputId":"301418f0-654e-442d-ea8e-d4b22a388799"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["1.25.2\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n","    return self.__dep_map\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n","    raise AttributeError(attr)\n","AttributeError: _DistInfoDistribution__dep_map\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/show.py\", line 45, in run\n","    if not print_results(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/show.py\", line 150, in print_results\n","    for i, dist in enumerate(distributions):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/show.py\", line 104, in search_packages_info\n","    required_by = sorted(_get_requiring_packages(dist), key=str.lower)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/show.py\", line 94, in <genexpr>\n","    in {canonicalize_name(d.name) for d in dist.iter_dependencies()}\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n","    return self._dist.requires(extras)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n","    dm = self._dep_map\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n","    self.__dep_map = self._compute_dependencies()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n","    reqs.extend(parse_requirements(req))\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n","    super(Requirement, self).__init__(requirement_string)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n","    req = REQUIREMENT.parseString(requirement_string)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n","    loc, tokens = self._parse(instring, 0)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n","    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 856, in _parseNoCache\n","    tokens = fn(instring, tokens_start, ret_tokens)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 291, in wrapper\n","    ret = func(*args[limit:])\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 71, in <lambda>\n","    lambda s, l, t: Marker(s[t._original_start : t._original_end])\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/markers.py\", line 278, in __init__\n","    self._markers = _coerce_parse_result(MARKER.parseString(marker))\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n","    loc, tokens = self._parse(instring, 0)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n","    return super().parseImpl(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n","    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n","    loc, resultlist = self.exprs[0]._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n","    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 5226, in parseImpl\n","    return super().parseImpl(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n","    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n","    loc, resultlist = self.exprs[0]._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4375, in parseImpl\n","    return self.expr._parse(instring, loc, doActions, callPreParse=False)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n","    loc, exprtokens = e._parse(instring, loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n","    return e._parse(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 821, in _parseNoCache\n","    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3209, in parseImpl\n","    instring[loc] == self.firstQuoteChar\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n","    return run(options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n","    logger.critical(\"Operation cancelled by user\")\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n","    self._log(CRITICAL, msg, args, **kwargs)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n","    self.emit(record)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 172, in emit\n","    style = Style(color=\"red\")\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/style.py\", line 146, in __init__\n","    def _make_color(color: Union[Color, str]) -> Color:\n","  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n","    return cached(*args, **kwds)\n","  File \"/usr/lib/python3.10/typing.py\", line 403, in __getitem__\n","    return self._getitem(self, parameters)\n","  File \"/usr/lib/python3.10/typing.py\", line 521, in Union\n","    return _UnionGenericAlias(self, parameters)\n","  File \"/usr/lib/python3.10/typing.py\", line 1016, in __init__\n","    def __init__(self, origin, params, *, inst=True, name=None,\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"markdown","source":["# Loading, Preprocessing, Tokenizing\n","\n","Below sections are meant for:\n","\n","1. Loading in the dataset. We are currently using the Model-Written-Evals Agreeableness dataset by Anthropic\n","\n","2. Tokenizing the dataset. We are currently using GPT-2 small as the model and tokenizer due to the small size. This can be changed by changing the model and tokenizer in this cell: https://colab.research.google.com/drive/1qUdsegUIZILv5DDLVStH6GTIz-ZhFmKH#scrollTo=h99FH4xDP2Y4&line=16&uniqifier=1\n","\n","3. Pre-processing: Generating activation deltas. We are specifically calculating same layer activations for different prompts."],"metadata":{"id":"nWdyRGUEI0tS"}},{"cell_type":"code","source":["#@title Globally used variables\n","\n","DEBUG = True\n","\n","# Model and tokenizer\n","MODEL_NAME = 'google/gemma-2b'\n","TOKENIZER = \"google/gemma-2b\"\n","\n","# Initialize Max Length of Tokens\n","MAX_PADDED_LENGTH = None\n","\n","# layer of interest for this run\n","# Needs to be constant for cached activations and SAE training\n","LAYER = 9\n","\n","# This is the path for a shared drive\n","# Add the drive to your Google Drive by adding a shortcut as per\n","# https://stackoverflow.com/questions/54351852/accessing-shared-with-me-with-colab\n","DATASET_PATH = \"/content/drive/MyDrive/Hackathon: Contrastive SAE Steering/datasets/agreeableness.json\"\n","DRIVE_PATH = \"/content/drive/MyDrive/Hackathon: Contrastive SAE Steering\"\n","\n","SV_PROMPT = \"The thought of harming another person is exciting to me\"\n","\n","# Arbitrary large padded length to keep everything the same\n","MAX_PADDED_LENGTH = 30"],"metadata":{"id":"rTtd__p9LrsS","executionInfo":{"status":"ok","timestamp":1720298169724,"user_tz":240,"elapsed":216,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","# Need a hugging face token with READ permissions to access Gemma-2b\n","\n","hf_token = userdata.get('hf_token')"],"metadata":{"id":"oh5dEp1ULJDL","executionInfo":{"status":"ok","timestamp":1720298268731,"user_tz":240,"elapsed":751,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"h99FH4xDP2Y4","collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":246,"referenced_widgets":["5fa3ffa17d1c4c389a9f11768ff1e7b8","8d3d9fad22954974a0346d02f694b5d4","bc3ad7e81baf4d7db350312f9388e997","f0b8de0ec9fd41a8ad388060062ce79a","81ace3d80c414426a39fe64123a52a28","859ad9c1b3a0433882932ee74dc71c89","4b6020415e164d6893d2b7f4d8a61b6d","485b14c8dde04ae3967555f0bdc4c1f0","aa634657bbc148249d9ebe926f640d13","fcdfe3ec4a9946ed880e403c0a8c9292","5d08c23e82a54adbab4dce7417a64ef3","11809105110c489090c58a92f2eb81f2","edda6322278749b9a96a0153ad05e0ee","7ca7ae443b5940c89598a2682e97831a","a2b2afcbaa2a449aa3242e00827afcb9","3a02b87f92a34e0485ba55ccc28d5a4c","97937598e5514b1b8506a64c2d090c75","b3aa161bb6e64b4b9165ddb2501a82fd","97a582b4b004432fafeec417637240ea","34bf96dbe4194cfba5b3c689b3f3beae","3e55b155bd294b109b818dc9f740ded6","3e867c1f259c47ba825cea244f380035","ef19fa29695c4ed7bac16863b8894543","bdd9ee241f0f46718bb4495c17a8f75d","402e2112effc4362aae4deb9610a6ab6","ebd0d5c88e0d47589fd0c9117f62ec8c","0375306c4e414bd4b7edcf9e23861eb6","49f4fa99cf7f48fd84beeec8adf33001","bd289b2c249d4184b7b4d04543864c1e","99a921d6b64e4bc599bc93e799c813f0","220f262b298e44aaac44e28a0de964be","8f240807b554431abd33c7e134658f12","82290620353b43f39ca3ee99305fe06a","21b0a6e18bfe495fbd2f5562c726a4f9","4ce78b20166143babee7946ba64cafae","521a7afbc08f4aa09b844062cd3418a3","f6c4d968e20b4e69b00d183cd86aab17","fc82d61ac46b477b8cadbc6ce4e5c1d3","de7cb68bfb38426c85c6c509dfb4c6ea","2977e7e046e442f9b84060d9f9852a38","c01d9f78d9d9467b95b4ea2ae2d87f64","afe26f55b74a4d89bf41ed61f009eda4","d1c8d51db59a438e98a8880b6237e5db","52ac43164bf74c00b925afc8ea5c9ba0","57de5a7efd2c4ade825ae82deb1fcdce","cb65e3910f7d4f778ba3ceeb89ebd069","9384e134671d4b6286437c4b81f3f9eb","5e70e88f69884eabbb1c410a7c736857","3c0e45b995534534a98b786ef2e2ba55","90090d8a640a4e848f54d6ba493e4322","b92573e791f74828a5db485829ad7035","905e46a8c6cb4b288865cf56686ff762","016fd869396448c284be056fcfb96fdf","dc462de1d5f04d299942cc2917ac2e39","835fc0261ad84c20a708c57e2d418952"]},"executionInfo":{"status":"ok","timestamp":1720298394497,"user_tz":240,"elapsed":5574,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}},"outputId":"d2c23f5c-4730-4f15-c1e7-32fcf744d342"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fa3ffa17d1c4c389a9f11768ff1e7b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11809105110c489090c58a92f2eb81f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef19fa29695c4ed7bac16863b8894543"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b0a6e18bfe495fbd2f5562c726a4f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57de5a7efd2c4ade825ae82deb1fcdce"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n","Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n","`config.hidden_activation` if you want to override this behaviour.\n","See https://github.com/huggingface/transformers/pull/29402 for more details.\n"]}],"source":["#@title Load Contrastive Dataset and Tokenizer\n","import torch\n","import pickle\n","import json\n","from scipy.cluster import hierarchy\n","from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from transformer_lens.hook_points import HookPoint\n","from nnsight import LanguageModel\n","\n","from accelerate import Accelerator\n","\n","# # FOR GPU:\n","# accelerator = Accelerator()\n","# device = 'cuda'\n","# device = accelerator.device\n","\n","# FOR TPU\n","device = 'tpu'\n","accelerator = Accelerator()\n","device = accelerator.device\n","\n","quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n","\n","#load gpt 2 small and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER, token=hf_token)\n","model = LanguageModel(MODEL_NAME, low_cpu_mem_usage=False, token=hf_token, quantization_config=quantization_config)\n","\n","with open(DATASET_PATH) as f:\n","  prompts = json.load(f)\n"]},{"cell_type":"code","source":["#@title Prepare Prompts\n","\n","# preparing the contrastive prompts\n","# right now I'm using a sample but we can easily generate them from Anthropic's Model-Written-Evals\n","\n","tokenized_prompts = []\n","\n","for i in range(len(prompts)):\n","    positive_prompt = prompts[i]['original_prompt']\n","    negative_prompt = prompts[i]['negative_prompt']\n","\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","    # pad both inputs to the MAX_PADDED LENGTH length so we can calculate differences later\n","    positive_input_padded = tokenizer(positive_prompt, return_tensors=\"pt\", padding='max_length', max_length=MAX_PADDED_LENGTH)\n","    negative_input_padded = tokenizer(negative_prompt, return_tensors=\"pt\", padding='max_length', max_length=MAX_PADDED_LENGTH)\n","\n","    tokenized_prompts.append(positive_input_padded)\n","    tokenized_prompts.append(negative_input_padded)\n","\n","# the positive and negative prompts are paired A1A2B1B2C1C2...\n","# so if you want to get the 4th pair, you would index [7] and [8]\n","print(\"length of prompts\", len(tokenized_prompts))\n","print(\"prompt sequence length\", len(tokenized_prompts[9]['input_ids'][0]))\n","print(\"prompt sequence length\", len(tokenized_prompts[8]['input_ids'][0]))\n","\n","def check_same_length(tokenized_prompts):\n","  for i in range(0, len(tokenized_prompts)):\n","    if len(tokenized_prompts[i]['input_ids'][0]) != MAX_PADDED_LENGTH:\n","      return False\n","  return True\n","\n","# Sanity check that all the prompt pairs are the same length\n","assert(check_same_length(tokenized_prompts))"],"metadata":{"id":"aBqFgRM-jW8k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720298399986,"user_tz":240,"elapsed":191,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}},"outputId":"debc7550-b1e9-4276-80b5-55eac5d4cc76"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["length of prompts 20\n","prompt sequence length 30\n","prompt sequence length 30\n"]}]},{"cell_type":"code","source":["#@title Print Positive Prompts\n","\n","# print out all the positive prompts just to see what's happening\n","\n","positive_prompts = []\n","for i in range(0, len(tokenized_prompts), 2):\n","  positive_prompts.append(tokenized_prompts[i])\n","\n","print(positive_prompts)"],"metadata":{"id":"B5IPu-8gIasH","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720298407948,"user_tz":240,"elapsed":153,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}},"outputId":"77719f37-a949-4eb5-ec64-a5f0d364a060"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              2,   1718, 235303, 235256,   2845,    577,   3516,   1461,  35167,\n","            578,   2369,   2823]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      2, 235285,   4313,   1855,\n","          25201,    577,   3588]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      2,   1718,    603,   2845,    577,    614, 117240,    578,\n","          10055,    577,   3588]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              2, 235285,   4313,   1855,  30143,    577,   3588, 235269,   1855,\n","           2714,    603,   2245]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      2,   1718,    603,   2845,    577,    614,   8377,    578,\n","         117240,    577,   3588]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      2, 235285,\n","           3385,  52494,  75000,   1233,    578,   4692,  19456,    604,    476,\n","           1508,   1497,   1069]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      2, 235285,\n","           4313,  12393,   3588,    578,   2212,   1105,   1024,  18821,    578,\n","           1578, 235290,  16978]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      2,    651,   3421,    576, 163335,   2550,   1552,    603,\n","          17305,    577,    682]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      2,  26424,   1412,    614,  11017,    675,  36156, 235269,\n","          35438,    578,   6207]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}, {'input_ids': tensor([[     1,      1,      1,      1,      1,      1,      1,      1,      1,\n","              1,      1,      1,      1,      1,      1,      1,      1,      2,\n","         235285,    791,    793,  11115,    604,   1156,   1461, 235303, 235256,\n","           4026,    578,  14690]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1]])}]\n"]}]},{"cell_type":"markdown","source":["## Preprocessing\n","\n","Below, we are generating and calculating all activation deltas. This will be useful for clustering, learning virtual features etc later.\n","\n","Basically:\n","\n","1. Define layer of interest (global variable)\n","2. Get layer output of running the prompt through the model\n","3. Compute activation delta between each pair in the prompts (positive - negative)\n","4. Get average activation delta for all the pairs\n","5. Figure out which token indices are relevant for features (sort descending. Intuitively, 0 delta implies unimportance, and starting tokens tend to be 0-like)"],"metadata":{"id":"KjmJHU0NFyMY"}},{"cell_type":"code","source":["print(model)"],"metadata":{"id":"N7lGsiRzL66c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","\n","# Initialize a list to store all activations\n","all_activations = []\n","\n","for i in range(len(tokenized_prompts)):\n","  with model.trace(tokenized_prompts[i]['input_ids']):\n","    if i % 2 == 0: # if index is even, positive prompt\n","      prompt_type = 'positive'\n","    else:\n","      prompt_type = 'negative'\n","    # There should be a better way of doing this\n","    # This below this is kind of hardcoded\n","    output = model.model.layers[LAYER].output.save()\n","\n","    pair_num = math.floor(i / 2) + 1\n","\n","  # print(f\"{prompt_type} in {pair_num} prompt:  {output}\")\n","  # print(f\"shape of output: {output.shape}\")\n","\n","  # Store the activation\n","  all_activations.append(output.value[0])\n","\n","def check_activation_shapes(all_activations):\n","  activation_shape = all_activations[0].shape\n","  for activation in all_activations[1:]:\n","    if activation.shape != activation_shape:\n","      return False\n","  return True\n","\n","# Sanity check that all the activations are the same shape\n","assert(check_activation_shapes(all_activations))\n","\n","# Make a new tensor to store the unaveraged activations\n","# as we will do operations on the other tensor later\n","unavg = all_activations\n","print(f\"Number of activations stored: {len(unavg)}\")\n","print(f\"Activation Shape: {unavg[0].shape}\")\n","\n","import torch\n","\n","# Calculate cosine similarity\n","cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n","similarity_0_1 = cos(torch.tensor(all_activations[0]), torch.tensor(all_activations[1]))\n","similarity_0_2 = cos(torch.tensor(all_activations[0]), torch.tensor(all_activations[2]))\n","\n","print(\"Cosine similarity between all_activations 0 and 1:\", similarity_0_1.mean().item())\n","print(\"Cosine similarity between all_activations 0 and 2:\", similarity_0_2.mean().item())"],"metadata":{"id":"on18gB36kKSS","collapsed":true,"colab":{"base_uri":"https://localhost:8080/","height":724,"referenced_widgets":["dfc7bfca9c5142db99613bba34f5f5d5","6233225de30c4c53a91cfae7a0944a6e","9a0af0eec9ca465d9d4e19e63a0618ff","01a2ae5a0f60426ba14d8c78950c9476","f16dc6eccbd545a0b8b4b78ce44f1fe0","a6ddda72e44647109bd5a5c7c4e78f5c","b9c7821effb74d3e9ae1f245f5604587","43a7b4b6561c49eeba414bcae98145e8","01ea2ff250954aa0827fab63fe2fbc7a","98e62f4e48b442109edc3314d8bf1d94","98123449691e43f4bfc6ef606ffec23c","9572bb5a21f846debfc9a049cd2329c4","83176dcd72a0468992c53295476e2fc7","0237455e51d6446f8b4aaaf975f8e3ac","2d1e22f591454e05a5c0d1456109441e","44ce33b1f5a04af0b5bed32032699847","e464894752834e8e921ec860cab55117","6134cb050863492db2ff95be8c24b8e0","5a62ee8ed9244c549a3ae0fbb61e9746","30614434a96a4a98bb6ad7a9b9536458","df34a86f000342e8aa64e51ecb5f2d18","e7ccef89f0fb411bb9e2ec667a56df43","f4e2602c35fd4232ae05fb7b36467e9f","d1ae58cedad840b49def4b313b230f88","c09a431eaf234b4181811b35f5bc4cac","d68fc6d799a946aa84e4045861e45566","4f8c85dcb918439f91b9b335135a7724","9cfc0df4ce744e2ea9e040842ccbceb7","052c2dfa20614f28a74b34ec44a420be","d0f622bf13f0481f99fff36bcfcf1ef6","b3adec10ec394fb89effbb2ef9ab1bce","5aa2a3e0ec3240ed9529013c0a794674","7065a44e12c842fa8fb06dba60993fc9","edbfa156a90a4d469165b7eed2d63d87","501a0f63d38f44c09bc3630dcb091937","df04e81ba1af4e4a928addbb0691876b","8735bcee310744b7afdbec883506499e","36f3bb3ce120494494bcb86a6d3f9c17","357b0e7012d0409d844743337999deab","3d5898e5d9ad4c77812fb7d26d794247","993b9fb55b2b4216b9564895eb643615","2e73d6e83ff44c53ba463b8780322ab9","e0ba34db2ac445529c6e4e326027ca69","0261d7ba5747456b938f9207f0ce36cf","51cf7cb4d7f24a0baf9cfc0472b2e7a0","522394fb6a70462a80cfa721b8f2e97e","cc97ff08a0ee4d818bc6f78f3296131a","ee3567375f8449ef93d7fdb0735124cc","46ad490e469f40eaa90265eccfcd5bff","a766483672c547509a9368e3f1d950f9","e8d51601721c4c8c88d869217445d284","377c0946605f4a42ac53873be4e31a57","047f1c0bd0404a0c97a73137c541d49c","b79668988f2f45ef8d19f9a583d770d7","f6eae777d25e4186abd1611c09cfbf08","474e005f036a43dc98546668dcc10230","be6597dc3dab4c98af0945878e000c5a","b73f808e8f4648b3aa76cdf198186a38","5ac758653db44a008c3942fb55135065","f5a2f68ae05f4ed7801c82a260a590ea","3c43577cd73e4787ad2050ae2f680c3b","13664e911b024cfd82e70b3870abbae1","17ae0bc61212462da1df235bf7e6114a","31d8649416a54886a864b9b88f740839","0b4bde7d35c54cbaab87cf15a6424088","f8e7850c1e6f42ab88d53b98196d200c"]},"executionInfo":{"status":"error","timestamp":1720298498192,"user_tz":240,"elapsed":86741,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}},"outputId":"caaa328e-9269-4a60-b4d0-7c1b33457576"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfc7bfca9c5142db99613bba34f5f5d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9572bb5a21f846debfc9a049cd2329c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4e2602c35fd4232ae05fb7b36467e9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edbfa156a90a4d469165b7eed2d63d87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51cf7cb4d7f24a0baf9cfc0472b2e7a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"474e005f036a43dc98546668dcc10230"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:426: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"TypeError","evalue":"Multiple dispatch failed for 'torch._ops.aten.t.default'; all __torch_dispatch__ handlers returned NotImplemented:\n\n  - mode object <torch._subclasses.fake_tensor.FakeTensorMode object at 0x78dcb03b8040>\n\nFor more information, try re-running with TORCH_LOGS=not_implemented","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-7b6ef22be18c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_prompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_prompts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# if index is even, positive prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mprompt_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'positive'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/models/NNsightModel.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(self, trace, invoker_args, scan, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;31m# Otherwise open an invoker context with the give args.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minvoker_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# If trace is False, you had to have provided an input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/contexts/Invoker.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             ) as fake_mode:\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mFakeCopyMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                     self.tracer._model._execute(\n\u001b[0m\u001b[1;32m     70\u001b[0m                         \u001b[0;34m*\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/models/mixins/Generation.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, prepared_inputs, generate, *args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_generate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprepared_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     def _scan(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nnsight/models/LanguageModel.py\u001b[0m in \u001b[0;36m_execute_forward\u001b[0;34m(self, prepared_inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         return self._model(\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mprepared_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 for hook_id, hook in (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1099\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 for hook_id, hook in (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    900\u001b[0m                 )\n\u001b[1;32m    901\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    903\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 for hook_id, hook in (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         hidden_states, self_attn_weights, present_key_value = self.self_attn(\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 for hook_id, hook in (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/gemma/modeling_gemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m                 for hook_id, hook in (\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\u001b[0m in \u001b[0;36mnew_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul_4bit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquant_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_subclasses/fake_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Multiple dispatch failed for 'torch._ops.aten.t.default'; all __torch_dispatch__ handlers returned NotImplemented:\n\n  - mode object <torch._subclasses.fake_tensor.FakeTensorMode object at 0x78dcb03b8040>\n\nFor more information, try re-running with TORCH_LOGS=not_implemented"]}]},{"cell_type":"code","source":["# compute activation deltas between each pair (total of 10 pairs in this sample)\n","activation_deltas = [unavg[i] - unavg[i + 1] for i in range(0, len(unavg), 2)]\n","print(len(activation_deltas))\n","\n","# calculate the mean activation delta across all pairs\n","# TODO: do this for all pairs not just one prompt number\n","prompt_num = 8\n","torch.set_printoptions(profile=\"full\")\n","print(activation_deltas[prompt_num])\n","torch.set_printoptions(profile=\"default\")\n","diff_act_mean = activation_deltas[prompt_num].mean(dim = 1)\n","abs_diff_act_mean = torch.abs(diff_act_mean)\n","print(\"absolute difference in activation before sort\", abs_diff_act_mean)\n"],"metadata":{"id":"rckqHd9Bpdqu","collapsed":true,"executionInfo":{"status":"aborted","timestamp":1720298498195,"user_tz":240,"elapsed":6,"user":{"displayName":"sinem erisken","userId":"10098141094175015247"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sort the token positions according to abs activation delta in descending order\n","sorted_indices =  torch.argsort(abs_diff_act_mean, descending = True)\n","print(f\"descending sort indices: {sorted_indices}\")\n","\n","# Filter zero-valued indices in O(n) time\n","# TODO Remove Magic Number\n","filtered_indices = [idx.item() for idx in sorted_indices if abs_diff_act_mean[idx] > 0.0001]\n","print(f\"Filtered non-zero indices: {filtered_indices}\")"],"metadata":{"id":"5-6kLqK32i0Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sanity check: encode and decode the prompt using gpt2 tokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(TOKENIZER)\n","text = prompts[prompt_num]['original_prompt']\n","encoded_text_pos = tokenizer.encode(text)\n","decoded_text_pos = tokenizer.decode(encoded_text_pos)\n","print(f\"Original Positive Text: {text}\")\n","print(f\"Encoded text: {encoded_text_pos}\")\n","decoded_text_list = decoded_text_pos.split()\n","for i, token in enumerate(decoded_text_list):\n","    print(f\"Token: {i}: {token}\")\n","\n","text_neg = prompts[prompt_num]['negative_prompt']\n","encoded_text_neg = tokenizer.encode(text_neg)\n","decoded_text_neg = tokenizer.decode(encoded_text_neg)\n","print(f\"Original Negative Text: {text_neg}\")\n","print(f\"Encoded text: {encoded_text_neg}\")\n","decoded_text_list = decoded_text_neg.split()\n","for i, token in enumerate(decoded_text_list):\n","    print(f\"Token: {i}: {token}\")\n","\n","diff_indices = [i for i, (pos, neg) in enumerate(zip(encoded_text_pos, encoded_text_neg)) if pos != neg]\n","diff_indices += list(range(min(len(encoded_text_pos), len(encoded_text_neg)), max(len(encoded_text_pos), len(encoded_text_neg))))\n","print(\"Indices where tokens differ:\", diff_indices)"],"metadata":{"id":"DuXDvKGn5eui"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For prompt 8, it seems that although the token positions 5, 7, and 9 are changed by intervention, the activation patterns also effect 6 and 8, most likely due to the intervention on the previous token. Let's visualize the attention pattern at these positions using TransformerLens"],"metadata":{"id":"YMDpMvgt93mE"}},{"cell_type":"code","source":["# Load the GPT-2 model\n","from transformer_lens import HookedTransformer\n","model = HookedTransformer.from_pretrained(MODEL_NAME, tokenizer=tokenizer)"],"metadata":{"id":"u9ZH1j2BwE-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformer_lens import utils\n","import circuitsvis as cv\n","\n","VISUALIZE_PADDED = False\n","\n","# Define your input text\n","pos_text = prompts[prompt_num]['original_prompt']\n","neg_text = prompts[prompt_num]['negative_prompt']\n","\n","## Can't get this working for some reason??\n","# def visualize_attention_heads(text, model):\n","#   text_tokens = model.to_tokens(text)\n","#   text_logits, text_cache = model.run_with_cache(text_tokens, remove_batch_dim=True)\n","#   attention_pattern = text_cache[\"pattern\", LAYER, \"attn\"]\n","#   print(f\"Attention Pattern Shape: {attention_pattern.shape}\")\n","#   text_str_tokens =  model.to_str_tokens(text)\n","#   print(f\"Layer {LAYER} Attention Patterns for {text}\")\n","#   cv.attention.attention_patterns(tokens=text_tokens, attention=attention_pattern)\n","\n","\n","# Tokenize the input\n","pos_tokens = model.to_tokens(pos_text)\n","neg_tokens = model.to_tokens(neg_text)\n","\n","if VISUALIZE_PADDED:\n","  # Tokenized and padded input from our tokenizer\n","  pos_tokens = tokenized_prompts[prompt_num]['input_ids']\n","  neg_tokens = tokenized_prompts[prompt_num + 1]['input_ids']\n","\n","# Run the model to get positive and negative prompt logits/cache\n","pos_logits, pos_cache = model.run_with_cache(pos_tokens, remove_batch_dim=True)\n","neg_logits, neg_cache = model.run_with_cache(neg_tokens, remove_batch_dim=True)"],"metadata":{"id":"ndQZJy2YtUMB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(pos_cache))\n","attention_pattern = pos_cache[\"pattern\", LAYER, \"attn\"]\n","print(attention_pattern.shape)\n","pos_str_tokens = model.to_str_tokens(pos_text)\n","\n","print(f\"Layer {LAYER} Head Attention Patterns for POSITIVE:\")\n","cv.attention.attention_patterns(tokens=pos_str_tokens, attention=attention_pattern)"],"metadata":{"id":"MciRych1wYaq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(pos_cache))\n","attention_pattern = neg_cache[\"pattern\", LAYER, \"attn\"]\n","print(attention_pattern.shape)\n","neg_str_tokens = model.to_str_tokens(neg_text)\n","\n","print(f\"Layer {LAYER} Head Attention Patterns for NEGATIVE:\")\n","cv.attention.attention_patterns(tokens=neg_str_tokens, attention=attention_pattern)"],"metadata":{"id":"YMd9cBt5wer0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Finding Features Using Tokens\n"],"metadata":{"id":"d-EU9arfLQsq"}},{"cell_type":"code","source":["import os\n","import sys\n","sys.path.append(DRIVE_PATH)\n","os.chdir(DRIVE_PATH)\n","\n","from transformer_lens import HookedTransformer\n","from sae_lens import SAE\n","from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n","\n","device = 'cpu'\n","\n","model = HookedTransformer.from_pretrained(MODEL_NAME, device = device, tokenizer=tokenizer)\n","model.tokenizer.pad_token = model.tokenizer.eos_token\n","model.tokenizer.pad_length = MAX_PADDED_LENGTH\n","\n","# get the SAE for this layer\n","# TODO: Clean this up, make a global variable, etc etc?\n","sae, cfg_dict, _ = SAE.from_pretrained(\n","    release = \"gpt2-small-res-jb\",\n","    sae_id = f\"blocks.{LAYER}.hook_resid_pre\",\n","    device = device\n",")\n","\n","# get hook point\n","hook_point = sae.cfg.hook_name\n","print(hook_point)"],"metadata":{"id":"v1nk3Q1mLKRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","sv_prompt = \"Everyone should be treated with kindness, dignity and respect\"\n","sv_tokens = model.tokenizer(sv_prompt, return_tensors=\"pt\", padding='max_length', max_length=MAX_PADDED_LENGTH)\n","sv_logits, cache = model.run_with_cache(sv_tokens['input_ids'], prepend_bos=True, remove_batch_dim=True)\n","\n","# if DEBUG:\n","#   print(\"tokens\", tokens)\n","#   print(\"logits\", sv_logits)\n","#   print(\"cache\", cache)\n","\n","# feature activations from our SAE\n","sv_feature_acts = sae.encode(cache[hook_point])\n","\n","# top k activations\n","topk = torch.topk(sv_feature_acts, 3)\n","\n","# This is a list of activation values (higher number == more activation)\n","acts = topk[0]\n","if DEBUG:\n","  print(\"Activations\")\n","  print(acts)\n","\n","#This is a list of feature identities that Neuronpedia will have collected\n","features = topk[1]\n","if DEBUG:\n","  print(\"Features\")\n","  print(features)\n","\n","all_feats = []\n","for feat in features[filtered_indices]:\n","    all_feats.append(feat.tolist())\n","\n","\n","## Nudging should no longer be needed thanks to the padding being equal for everyone\n","# print(\"Indices before nudge\", (filtered_indices))\n","\n","# # avoid index out of bounds and move all indices by the diff\n","# # taking care of off by one errors\n","# diff = max(filtered_indices) - len(features[0]) + 1 if max(filtered_indices) >= len(features[0]) else 0\n","# nudged_indices = [idx - diff for idx in filtered_indices]\n","\n","# print(\"Indices after nudge\", nudged_indices)\n","# print(\"Nudged acts\", acts[0][nudged_indices])\n","# print(\"Nudged feature indices\", features[0][nudged_indices])\n","\n","# all_feats = []\n","# for feat in features[0][nudged_indices]:\n","#     all_feats.append(feat.tolist())\n","\n","# Convert the nested list to a NumPy array and python set\n","flat_feat_list = np.array(all_feats).flatten().tolist()\n","print(\"number of features collected\", len(flat_feat_list))\n","feature_set = set(flat_feat_list)\n","print(\"number of unique features collected\", len(feature_set))"],"metadata":{"id":"ZiUnCyxOM0Zg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n","\n","print(\"SAE features for relevant indices as per activation delta\")\n","get_neuronpedia_quick_list(list(feature_set), layer = LAYER)"],"metadata":{"id":"rmx0L_mDL4rX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hybrid Clustering\n","We want to find as many features related to this persona.\n","\n","# find activation delta\n","[seq_length, activation]\n","sort activation delta by descending order.\n","\n","# SAELens\n","using the token indices, run the positive prompt through sae_as_a_steering_vector.ipynb and grab features indices. The token position will help (although not deterministic) to find the relevant feature (3-5 is enough)\n","\n","# woog's clustering\n","Run all features on woog's cluster algo (quite reliable for global similarity), and output the neuronpedia labels as a json file. manually eliminate some spurious features.\n","\n","# run (weighted) linear regression\n","Once we have the full set of relevant sae features, run regression with the sae feature as input and activation dim / activation as target. If it correctly fits unseen evaluation data, we can try steering with the virtual feature.\n","\n","\n","\n"],"metadata":{"id":"-0HDfgRN_Bat"}},{"cell_type":"code","source":["# Initialize a dictionary\n","activation_dict = {}\n","\n","# Iterate over the feature set and extract the corresponding activation tensors\n","for idx in feature_set:\n","  activation_dict[idx] = sv_feature_acts[0][idx]\n","\n","print(activation_dict)"],"metadata":{"id":"Xx0cYSGYJxby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import einops\n","from typing import Dict\n","\n","def fit_features_to_activation_delta(\n","    feature_activations: Dict[int, torch.Tensor],\n","    activation_delta: torch.Tensor\n",") -> torch.Tensor:\n","    \"\"\"\n","    Fit a set of curated features to an activation delta using linear regression.\n","\n","    Args:\n","    feature_activations (Dict[int, torch.Tensor]): Dictionary mapping feature indices to their activation tensors.\n","    activation_delta (torch.Tensor): Target activation delta to fit.\n","\n","    Returns:\n","    torch.Tensor: Weights that maximize similarity to the activation delta.\n","    \"\"\"\n","    # Convert the dictionary to a list of tensors, preserving the order of indices\n","    feature_indices = sorted(feature_activations.keys())\n","    X = torch.stack([feature_activations[idx] for idx in feature_indices])\n","\n","    # Reshape X to (num_features, -1)\n","    X = einops.rearrange(X, 'features ... -> features (...)')\n","\n","    # Reshape y (activation_delta) to (-1,)\n","    y = einops.rearrange(activation_delta, '... -> (...)')\n","\n","    # Compute the weights using the normal equation\n","    weights = torch.linalg.lstsq(X.T, y).solution\n","\n","    return weights"],"metadata":{"id":"LIrU8g-EDMnO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["residual_outputs = []\n","\n","def hook_fn(module, input, output):\n","    residual_outputs.append(output)\n","\n","# Register hooks for each GPT2Block\n","for block in model.transformer.h:\n","    block.register_forward_hook(hook_fn)\n"],"metadata":{"id":"RjVHJqSJZUIR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","def flatten_and_cosine_sim(tensor1, tensor2):\n","    # Flatten the tensors\n","    flattened1 = tensor1.view(tensor1.size(0), -1)\n","    flattened2 = tensor2.view(tensor2.size(0), -1)\n","\n","    if flattened1.shape != flattened2.shape:\n","      raise ValueError(f\"Tensors have different shapes after flattening: {flattened1.shape} vs {flattened2.shape}\")\n","\n","\n","    # Normalize the flattened tensors\n","    normalized1 = F.normalize(flattened1, p=2, dim=1)\n","    normalized2 = F.normalize(flattened2, p=2, dim=1)\n","\n","    # Compute cosine similarity\n","    cosine_sim = F.cosine_similarity(normalized1, normalized2)\n","\n","    return cosine_sim"],"metadata":{"id":"y2h7OoV_1Pz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pos_n_neg_cos = flatten_and_cosine_sim(all_activations[0], all_activations[1])\n","cos2 = flatten_and_cosine_sim(all_activations[2], all_activations[3])\n","cos3 = flatten_and_cosine_sim(all_activations[4], all_activations[5])\n","cos4 = flatten_and_cosine_sim(all_activations[6], all_activations[7])\n","cos5 = flatten_and_cosine_sim(all_activations[8], all_activations[9])\n","\n","print(pos_n_neg_cos.mean())\n","print(cos2.mean())\n","print(cos3.mean())\n","print(cos4.mean())\n","print(cos5.mean())"],"metadata":{"id":"l9Xp8Vvxxw8Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","import torch\n","import pickle\n","import json\n","from scipy.cluster import hierarchy\n","from transformers import Trainer, TrainingArguments, AutoModelForCausalLM, AutoTokenizer\n","from nnsight import LanguageModel\n","from accelerate import Accelerator\n","import math\n","# # Intro\n","# Typically we use cosine similarity as a proxy for relatedness of features.\n","# Normally to find nearest neighbors you would have to check all pairwise distances.\n","#\n","# By using a hierarchical clustering method in advance, we can precompute these to make retrieval near instant at inference time.\n","#\n","# # Contrastive Pair-Guided Clustering: July 2024 Mech Interp Hackathon Feature Clustering Algorithm\n","# In this notebook, we try a contrastive-pair guided clustering to cluster the dataset into two clusters. Then we visualize the clusters as a binary tree.\n","# While we traverse this tree, we identify the top-k features correlated with these sub-clusters and output the set of features maximally correlated to that specific sample dataset.\n","# We can then use a grid-search like algorithm to find the right linear combinations that minimizes loss on an eval dataset\n","#\n","#\n","#\n","# This indexing data over feature space takes minimal space: about 9 MB for ~300k features across the 12 layers of GPT2-small.\n","# It takes about 4 minutes per layer of ~25k features to compute, or about 45 minutes for all layers. These were all saved to a pkl.\n","# mount your drive\n","drive.mount('/content/drive')\n","!pip show accelerate\n","#@title to compute your own linkage matrices\n","\n","\n","accelerator = Accelerator()\n","device = 'cuda'\n","device = accelerator.device\n","\n","#load gpt 2 small and tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n","model = LanguageModel('gpt2', low_cpu_mem_usage=False)\n","\n","with open('/content/agreeableness.json') as f:\n","  prompts = json.load(f)\n","\n","prompts\n","\n","## This code is above already\n","# tokenized_prompts = []\n","\n","# for i in range(len(prompts)):\n","#     positive_prompt = prompts[i]['original_prompt']\n","#     negative_prompt = prompts[i]['negative_prompt']\n","\n","#     # tokenize without padding first\n","#     positive_inputs = tokenizer(positive_prompt, return_tensors=\"pt\", padding=False)\n","#     negative_inputs = tokenizer(negative_prompt, return_tensors=\"pt\", padding=False)\n","\n","#     # determine the max length between positive and negative inputs\n","#     max_length = max(positive_inputs['input_ids'].size(1), negative_inputs['input_ids'].size(1))\n","\n","#     tokenizer.pad_token = tokenizer.eos_token\n","\n","#     # pad both inputs to the same length so we can calculate differences later\n","#     positive_inputs_padded = tokenizer(positive_prompt, return_tensors=\"pt\", padding='max_length', max_length=max_length)\n","#     negative_inputs_padded = tokenizer(negative_prompt, return_tensors=\"pt\", padding='max_length', max_length=max_length)\n","\n","#     # append the padded inputs to tokenized_prompts\n","#     tokenized_prompts.append(positive_inputs_padded)\n","#     tokenized_prompts.append(negative_inputs_padded)\n","\n","# # the positive and negative prompts are paired A1A2B1B2C1C2...\n","# # so if you want to get the 4th pair, you would index [7] and [8]\n","# print(\"lenght of prompts\", len(tokenized_prompts))\n","# print(tokenized_prompts[18])\n","# print(tokenized_prompts[19])\n","\n","\n","\n","# # Initialize a list to store all activations\n","# all_activations = []\n","\n","# for i in range(len(tokenized_prompts)):\n","#   with model.trace(tokenized_prompts[i]['input_ids']):\n","#     if i % 2 == 0: # if index is even, positive prompt\n","#       prompt_type = 'positive'\n","#     else:\n","#       prompt_type = 'negative'\n","#     output = model.transformer.h[7].attn.output.save()\n","\n","#     pair_num = math.floor(i / 2) + 1\n","\n","#   # print(f\"{prompt_type} in {pair_num} prompt:  {output}\")\n","#   # print(f\"shape of output: {output.shape}\")\n","\n","#   # Store the activation\n","#   all_activations.append(output.value[0])\n","\n","# print(\"all activations length\", len(all_activations))\n","\n","\n","# print(\"real diff\", abs(all_activations[1]- all_activations[0]).mean())\n","# print(\"real diff\", abs(all_activations[3]- all_activations[2]).mean())\n","\n","import torch\n","\n","# Calculate cosine similarity\n","cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n","similarity_0_1 = cos(torch.tensor(all_activations[0]), torch.tensor(all_activations[1]))\n","similarity_0_2 = cos(torch.tensor(all_activations[0]), torch.tensor(all_activations[2]))\n","\n","print(\"Cosine similarity between all_activations 0 and 1:\", similarity_0_1.mean().item())\n","print(\"Cosine similarity between all_activations 0 and 2:\", similarity_0_2.mean().item())\n","\n"],"metadata":{"id":"QgZyDjHt0e7-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qMeacBl88hWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U7H6f8UiyZs7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load your data in here\n","decoders = torch.rand([8, 1024, 256]) # e.g. 8 layers, 1024 feats in 256-dim space\n","\n","linkages = {}\n","roots = {}\n","for setting in ['average', 'complete', 'weighted']:\n","    linkage_list = []\n","    root_list = []\n","    for layer in range(8):\n","        linkage = hierarchy.linkage(decoders[layer], method = setting, metric = 'cosine')\n","        root_list.append(hierarchy.to_tree(linkage))\n","        linkage_list.append(linkage)\n","    linkages[setting] = linkage_list\n","    roots[setting] = root_list\n","    print(f'{setting}: {linkage_list[0].shape} for each of {len(linkage_list)} layers')\n","\n","with open('your_linkages.pkl', 'wb') as f:\n","    pickle.dump(linkages, f)"],"metadata":{"id":"y067zH3khfAk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title to download precomputed indices over GPT2-small residual stream SAEs\n","\n","#!pip install gdown\n","filepath = 'https://drive.google.com/u/0/uc?id=1RXoS3woiEU1aX_waL8q1Dr5xiOu4NIht'\n","destpath = 'linkages.pkl'\n","!gdown {filepath} -O {destpath}\n","\n","import pickle\n","from scipy.cluster import hierarchy\n","\n","with open('linkages.pkl', 'rb') as f:\n","    linkages = pickle.load(f)\n","\n","roots = {}\n","for key, value in linkages.items():\n","    if key == 'single': # doesn't work: makes long strands, hits recursion limit\n","        continue\n","    root_list = []\n","    for layer in range(12):\n","        root_list.append(hierarchy.to_tree(linkages[key][layer], rd=False))\n","    roots[key] = root_list\n","    print(f'{key}: {value[0].shape} for each of {len(value)} layers')"],"metadata":{"id":"f5Qp6gof7eMT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Helper methods\n","import json\n","import urllib.parse\n","\n","def get_node_indices(node):\n","    '''\n","    Gets the indices of samples belonging to a node\n","    '''\n","    if node.is_leaf():\n","        return [node.id]\n","    else:\n","        left_indices = get_node_indices(node.left)\n","        right_indices = get_node_indices(node.right)\n","        return left_indices + right_indices\n","\n","def find_node_path(layer, node_id, root):\n","    \"\"\"\n","    Finds the path from root node to the node with given node_id.\n","    Returns a list of choices ('left' or 'right') to traverse the path.\n","    \"\"\"\n","    def traverse(node, path=''):\n","        if node is None:\n","            return None\n","        if node.id == node_id:\n","            return path\n","        left_path = traverse(node.left, path + 'L')\n","        right_path = traverse(node.right, path + 'R')\n","        if left_path:\n","            return left_path\n","        if right_path:\n","            return right_path\n","        return None\n","\n","    return traverse(root)\n","\n","def get_cluster_by_path(path, root):\n","    \"\"\"\n","    Navigates the hierarchical clustering tree from the root node\n","    based on the given sequence of 'left' and 'right' choices.\n","    Returns the cluster node reached after following the path.\n","    \"\"\"\n","    node = root\n","    for direction in path:\n","        if direction == 'L':\n","            node = node.left\n","        elif direction == 'R':\n","            node = node.right\n","        else:\n","            raise ValueError(\"Invalid direction: {}\".format(direction))\n","    return node\n","\n","def get_neuronpedia_quick_list(\n","    features: list[int],\n","    layer: int,\n","    model: str = \"gpt2-small\",\n","    dataset: str = \"res-jb\",\n","    name: str = \"temporary_list\",\n","    setting: str = \"average\",\n","):\n","    url = \"https://neuronpedia.org/quick-list/\"\n","    name = urllib.parse.quote(name)\n","    url = url + \"?name=\" + name\n","    list_feature = [\n","        {\"modelId\": model, \"layer\": f\"{layer}-{dataset}\", \"index\": str(feature)}\n","        for feature in features\n","    ]\n","    url = url + \"&features=\" + urllib.parse.quote(json.dumps(list_feature))\n","    print(url)\n","    return url\n","\n","def build_cluster(layer, feature_id, height=3, setting = 'average', verbose=True):\n","    layer = int(layer)\n","    root = roots[setting][layer]\n","    node_path = find_node_path(layer, feature_id, root)\n","    cluster_path = node_path[:-height]\n","    cluster = get_cluster_by_path(cluster_path, root=root)\n","    indices = get_node_indices(cluster)\n","    list_name = f'height {height} above L{layer}f{feature_id} with cluster setting: {setting}'\n","    url = get_neuronpedia_quick_list(indices, layer, name=cluster_path)\n","    if verbose:\n","        print(f'path to node: {node_path}')\n","        print(f'path to cluster: {cluster_path}')\n","        print(f'features in cluster: {indices}')\n","        return indices"],"metadata":{"id":"PQ9XAy7eY82n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # helper methods related to the contrastive pair\n","# import random\n","# import json\n","\n","# def create_contrastive_pairs(dataset, num_pairs=100):\n","#     contrastive_pairs = []\n","\n","#     for data in dataset:\n","#         question = data[\"question\"]\n","#         statement = data[\"statement\"]\n","#         answer_matching = data[\"answer_matching_behavior\"].strip()\n","#         answer_not_matching = data[\"answer_not_matching_behavior\"].strip()\n","\n","#         # Create positive example\n","#         positive_prompt = f\"{question}\\n{statement}\\nA) {answer_matching}\\nB) {answer_not_matching}\\nAnswer:\"\n","#         positive_completion = \" A\"\n","\n","#         # Create negative example\n","#         negative_prompt = f\"{question}\\n{statement}\\nA) {answer_matching}\\nB) {answer_not_matching}\\nAnswer:\"\n","#         negative_completion = \" B\"\n","\n","#         contrastive_pairs.append({\n","#             \"positive_prompt\": positive_prompt,\n","#             \"positive_completion\": positive_completion,\n","#             \"negative_prompt\": negative_prompt,\n","#             \"negative_completion\": negative_completion\n","#         })\n","\n","#     # Ensure we have at least the requested number of pairs\n","#     while len(contrastive_pairs) < num_pairs:\n","#         contrastive_pairs.extend(contrastive_pairs)\n","\n","#     # Randomly select the requested number of pairs\n","#     return random.sample(contrastive_pairs, num_pairs)\n"],"metadata":{"id":"eYdgrd4tSZ3h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # Specify dataset path\n","# dataset_path = ''\n","\n","# with open(dataset_path, 'r') as f:\n","#     dataset = [json.loads(line) for line in f]\n","\n","# # Create contrastive pairs\n","# contrastive_pairs = create_contrastive_pairs(dataset)\n","\n","# # Print a sample pair\n","# print(\"Sample contrastive pair:\")\n","# print(\"Positive prompt:\", contrastive_pairs[0][\"positive_prompt\"])\n","# print(\"Positive completion:\", contrastive_pairs[0][\"positive_completion\"])\n","# print(\"\\nNegative prompt:\", contrastive_pairs[0][\"negative_prompt\"])\n","# print(\"Negative completion:\", contrastive_pairs[0][\"negative_completion\"])"],"metadata":{"id":"II1aZei0U7jO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title #Usage\n","#@markdown Pick any layer, any feature from Joseph Bloom's GPT-2-small SAEs on the residual stream. Valid feature ids are between 0 and 24575.\n","\n","#@markdown `build_cluster` will return a list of features related to it, and a neuronpedia link to visualize of all of them.\n","\n","#@markdown If you use your own linkages for a different model, the features will still be related but the neuronpedia data won't be valid!\n","\n","#@markdown The `height` parameter controls how large the cluster is, by including more distant features.\n","\n","#@markdown If `height` is 6 or more, the URL might be too long to function.\n","\n","layer = \"9\" #@param [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n","feature_id = 2345 #@param {type: \"integer\"}\n","height = 2 #@param {type: \"slider\", min:1, max:8}\n","setting = 'average' #@param ['average', 'complete', 'weighted']\n","indices = build_cluster(\n","    layer=layer,\n","    feature_id=feature_id,\n","    height=height,\n","    setting=setting,\n",")"],"metadata":{"id":"xd9RJqKhoz6y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(indices)"],"metadata":{"id":"TBVCQfEpLsw2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since we have the clusters for a specific task, now we'll try to use the eval to steer the model in an interesting way\n","\n","```\n","# This is formatted as code\n","```\n","\n"],"metadata":{"id":"CpGC3iiMRMVk"}},{"cell_type":"markdown","source":[],"metadata":{"id":"2PjRaRANWC0g"}}]}